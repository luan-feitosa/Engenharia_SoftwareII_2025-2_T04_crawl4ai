# ğŸ§  Engenharia_SoftwareII_2025-2_T04_crawl4ai

### Projeto de AnÃ¡lise Arquitetural com Modelos de Linguagem (LLMs)

**Disciplina:** Engenharia de Software II â€“ UFS  
**Turma:** 2025/2 â€“ T04  
**Equipe:** Adriel Menezes Santana - 202100022659
Luan Feitosa Lima SÃ¡tiro - 202300061714
Luan Prata MendonÃ§a - 202000138885
Paulo Henrique Carvalho de Andrade - 202200060090
Paulo Henrique dos Santos Reis - 202100115524
Thiago Mecena Silva - 202100045840
Victoria Moura Santos - 202000138900

---

## ğŸš€ ExecuÃ§Ã£o no Google Colab

No GitHub, clique no botÃ£o
â€œOpen in Colabâ€:

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/luan-feitosa/Engenharia_SoftwareII_2025-2_T04_crawl4ai/blob/main/main.ipynb)

(ou use o link direto abaixo):

```bash
https://colab.research.google.com/github/luan-feitosa/Engenharia_SoftwareII_2025-2_T04_crawl4ai/blob/main/main.ipynb
```

---

## ğŸ” VisÃ£o Geral

Este projeto tem como objetivo aplicar **Modelos de Linguagem (LLMs)** para **analisar a arquitetura de software** de repositÃ³rios no GitHub, identificando padrÃµes arquiteturais, design patterns e caracterÃ­sticas estruturais (mÃ³dulos, camadas, dependÃªncias, etc).

AlÃ©m disso, o notebook compara os resultados obtidos em cada passo e gera um relatorio final comparando os padrÃµes encontrados.

---

## ğŸ§° Tecnologias Utilizadas

-   **Python 3.x**
-   **Google Colab** (execuÃ§Ã£o online, sem instalaÃ§Ã£o local)
-   **Bibliotecas:**
    -   `sentence_transformers`
    -   `requests`, `os`, `json`, `shutil`
    -   `numpy`
    -   `openai`
    -   `sklearn.cluster`
    -   `radon`

---

ğŸ’» Infraestrutura de AnÃ¡lise

Toda a metodologia de pipeline e a execuÃ§Ã£o dos trÃªs modelos de linguagem foram realizadas na plataforma Google Colab. Utilizamos o ambiente de execuÃ§Ã£o gratuito, que fornece acesso a GPUs NVIDIA T4 (ou similares, dependendo da disponibilidade no momento da execuÃ§Ã£o). Esta infraestrutura foi suficiente para carregar e executar todos os modelos de anÃ¡lise (Llama 3.1 8B, DeepSeek V3.2 Exp e Qwen 2.5 7B), permitindo que todo o pipeline de 6 etapas fosse concluÃ­do para cada modelo.

---

## ğŸ’» Como Executar (Metodologia de ComparaÃ§Ã£o)

1.  Abra o link do Google Colab.
2.  Instale as dependÃªncias (primeira cÃ©lula `!pip install...`).
3.  Coloque sua chave de API do Hugging Face na CÃ©lula 2.

**Para comparar os 3 Modelos:**

O notebook deve ser executado **trÃªs vezes**, uma para cada modelo.

4.  Na **CÃ©lula 2**, localize a variÃ¡vel `MODELO_HF`.
5.  Escolha um dos trÃªs modelos que analisamos:
    * `MODELO_HF = "meta-llama/Llama-3.1-8B-Instruct"`
    * `MODELO_HF = "deepseek-ai/DeepSeek-V3.2-Exp"`
    * `MODELO_HF = "Qwen/Qwen2.5-7B-Instruct"`
6.  Execute todas as cÃ©lulas em sequÃªncia (no menu, "Ambiente de execuÃ§Ã£o" > "Executar tudo").
7.  Salve o relatÃ³rio final gerado.
8.  Repita os passos 5 a 7 para os outros dois modelos.

**Justificativa dos Modelos:**
[cite_start]Selecionamos estes trÃªs modelos (Llama 3.1, DeepSeek V3.2, e Qwen 2.5) [cite: 634-636] por serem modelos de chat (Instruct) de tamanho similar (aprox. 7-8B de parÃ¢metros) e de alta performance, permitindo uma comparaÃ§Ã£o justa sobre como diferentes arquiteturas de LLM interpretam e analisam o cÃ³digo-fonte.

OBS: lembre de baixar o arquivo final e/ou salva-lo com um nome diferente pois quando rodar novamente com outra LLM o arquivo.md sera sobrescrito.

---

ğŸ“Š SaÃ­das Geradas

-   relatorios_passos.md â†’ RelatÃ³rios Markdown contendo:
    -   PadrÃµes arquiteturais detectados
-   relatorio_final.md:
    -   ComparaÃ§Ã£o entre resultados de cada passo.

(Arquivos salvos no diretÃ³rio atual do Colab ou no seu Drive, se montado.)

---

âœ… Funcionalidades Principais

-   ğŸ“‚ Clonagem local de repositÃ³rios GitHub (sem usar API externa).
-   ğŸ§© IdentificaÃ§Ã£o de padrÃµes arquiteturais e design patterns.
-   ğŸ“„ GeraÃ§Ã£o automÃ¡tica de relatÃ³rio em Markdown com o resultado da LLM usada.
